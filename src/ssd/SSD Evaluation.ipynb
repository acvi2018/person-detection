{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/amdegroot/ssd.pytorch/blob/master/eval.py\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../../../ssd.pytorch'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import cv2\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from ssd import build_ssd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate IOU\n",
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = (xB - xA + 1) * (yB - yA + 1)\n",
    "\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "\n",
    "# calculate TP,FP,FN from predictions and groundtruth\n",
    "def calculate_metrics(ground_truths, predictions, iou_threshold = 0.5):\n",
    "    '''\n",
    "    NOTE:\n",
    "    if in one image, we have multiple proposals for a particular object that is considered truly classified, \n",
    "    we only count one proposal as TP, and the others as FP\n",
    "    \n",
    "    TO DO : confidence based sorting to be done. But it won't affect TP,FP,FN\n",
    "\n",
    "    ground_truths : list of ground_truth in form of tuples (xmin,ymin,xmax,ymax)\n",
    "    predictions : list of prediction in form of tuples (xmin,ymin,xmax,ymax)\n",
    "    '''\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    pred_found_map = {i : False for i in range(len(ground_truths))}\n",
    "    if len(ground_truths) > 0:\n",
    "        if len(predictions) > 0:\n",
    "            for pred in predictions:\n",
    "                pred_found = False\n",
    "                for index, gt in enumerate(ground_truths):\n",
    "                    iou = bb_intersection_over_union(pred, gt)\n",
    "                    # print('IOU : {0}'.format(iou))\n",
    "                    if iou > iou_threshold:\n",
    "                        if pred_found_map[index] == False:\n",
    "                            TP = TP + 1\n",
    "                            pred_found = True\n",
    "                            pred_found_map[index] = True\n",
    "                            break\n",
    "                if pred_found == False:\n",
    "                    FP = FP + 1\n",
    "\n",
    "            if (len(ground_truths) - len(predictions)) > 0:\n",
    "                FN = FN + len(ground_truths) - len(predictions)\n",
    "        else:\n",
    "            FN = FN + len(ground_truths)\n",
    "    else:\n",
    "        if len(predictions) > 0:\n",
    "            FP = FP + len(predictions)\n",
    "    \n",
    "    return (TP, FP, FN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_metrics_for_image(model, img_file, ground_truth, cuda=False, person_class_index=15):\n",
    "    '''\n",
    "    Model will give all detections. We are only interested in person, person class index : 15\n",
    "    '''\n",
    "    \n",
    "    # TO DO : basic function args validation\n",
    "    \n",
    "    # read image and corresponding annotations\n",
    "    img = cv2.imread(img_file, cv2.IMREAD_COLOR)\n",
    "    rgb_image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    height, width, channels = img.shape\n",
    "\n",
    "    # subtracting mean from three channels\n",
    "    x = cv2.resize(img, (300, 300)).astype(np.float32) # input dimensions used\n",
    "    x -= (104.0, 117.0, 123.0) # mean of trained model\n",
    "    x = x.astype(np.float32)\n",
    "    x = x[:, :, ::-1].copy()\n",
    "    x = torch.from_numpy(x).permute(2, 0, 1)\n",
    "\n",
    "    # detections\n",
    "    xx = Variable(x.unsqueeze(0)) \n",
    "    if cuda:\n",
    "        xx = xx.cuda()\n",
    "    detections = model(xx).data\n",
    "\n",
    "    # Contains array of [probabilty, xmin, ymin, xmax, ymax]\n",
    "    person_detections = detections[0, person_class_index, :]\n",
    "\n",
    "    # scale back to original size\n",
    "    scale = torch.Tensor(rgb_image.shape[1::-1]).repeat(2)\n",
    "\n",
    "    # create array of predictions with confidence\n",
    "    predictions_conf_list = []\n",
    "    predictions_list = []\n",
    "\n",
    "    # iterate through the predicted detections\n",
    "    for i in range(person_detections.size(1)):\n",
    "        if person_detections[i][0] > 0.5:\n",
    "            predictions_conf_list.append((person_detections[i][0], (person_detections[i,1:] * scale).cpu().numpy()))\n",
    "            predictions_list.append((person_detections[i,1:] * scale).cpu().numpy())\n",
    "\n",
    "    TP, FP, FN = calculate_metrics([list(gt[0:4]) for gt in ground_truth], predictions_list)\n",
    "    # print('TP: {0}, FP: {1}, FN: {2}'.format(TP, FP, FN))\n",
    "    return (TP, FP, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights into state dict...\n",
      "Finished!\n",
      "Processing Normal_Follow_Day_Half_1_1_1 ...\n",
      "Processing BadParking_Static_Day_Half_1_1_1 ...\n",
      "Processing StealingInside_Follow_Day_Half_1_1_1 ...\n",
      "Processing StealingPedestrian_Follow_Day_Half_0_3_Rucksack_1 ...\n",
      "Processing Broken_CloseUp_Day_Half_1_1_2 ...\n",
      "Processing StealingPedestrian_Static_Day_Half_0_3_2 ...\n",
      "Processing Crash_Follow_Day_Half_0_2_2 ...\n",
      "Processing StealingCar_CloseUp_Day_Half_1_3_1 ...\n",
      "Processing StealingPedestrian_Static_Day_Half_0_3_1 ...\n",
      "Processing Suspicious_Static_Day_Half_0_2_1 ...\n",
      "Processing Normal_Static_Day_Half_1_1_1 ...\n",
      "Processing Normal_Circle_Day_Half_0_7_2 ...\n",
      "Processing Crash_Follow_Day_Half_0_2_1 ...\n",
      "Processing StealingCar_CloseUp_Day_Empty_1_m_1 ...\n",
      "Processing Normal_Circle_Day_Half_0_7_3 ...\n",
      "Processing Suspicious_Static_Day_Half_0_1_1 ...\n",
      "Processing Attack_CloseUp_Day_Empty_1_2_1 ...\n",
      "Processing Normal_Static_Night_Empty_1_3_1 ...\n",
      "Processing BadParking_Static_Day_Full_1_1_1 ...\n",
      "Processing Suspicious_Follow_Day_Half_0_m_1 ...\n",
      "Processing Normal_Follow_Day_Half_1_1_2 ...\n",
      "Processing Normal_Follow_Day_Half_0_1_1 ...\n",
      "Processing Suspicious_Follow_Day_Half_0_f_1 ...\n",
      "AP@0.5 : 78.46575342465754%\n",
      "Recall@0.5 : 7.06253698954429%\n"
     ]
    }
   ],
   "source": [
    "cuda = True\n",
    "\n",
    "# Load pretrained SSD model\n",
    "net = build_ssd('test', 300, 21)    # initialize SSD\n",
    "net.load_weights('../../../../ssd.pytorch/weights/ssd300_mAP_77.43_v2.pth')\n",
    "\n",
    "if cuda:\n",
    "    net.cuda()\n",
    "\n",
    "# initialize metrics\n",
    "TP_fin = 0\n",
    "FP_fin = 0\n",
    "FN_fin = 0\n",
    "\n",
    "# full data\n",
    "r_folder = '/home/vijin/iith/project/data/mini-drone-data_processed/test'\n",
    "for file in os.listdir(r_folder):\n",
    "    if os.path.isdir('{0}/{1}'.format(r_folder,file)):\n",
    "        \n",
    "        print('Processing {0} ...'.format(file))\n",
    "        # folder level details\n",
    "        video_file_name = file\n",
    "        folder = '{0}/{1}'.format(r_folder,file)\n",
    "        annotation_file_name = '{0}/{1}_ann.obj'.format(folder,video_file_name)\n",
    "        annotation_map = pickle.load(open(annotation_file_name,'rb'))\n",
    "        \n",
    "        # Iterate through the folder\n",
    "        for x in os.listdir(folder):\n",
    "            if '.jpg' in x:\n",
    "                frame_number_search = re.search('.*_frame_(\\d+).jpg', x, re.IGNORECASE)\n",
    "                if frame_number_search:\n",
    "                    frame_number = int(frame_number_search.group(1))\n",
    "                    if frame_number in annotation_map.keys():\n",
    "                        img_file = '{0}/{1}'.format(folder,x)\n",
    "                        ground_truth = annotation_map[frame_number]\n",
    "                        TP, FP, FN = calculate_metrics_for_image(net, img_file, ground_truth, cuda)\n",
    "                        TP_fin += TP\n",
    "                        FP_fin += FP\n",
    "                        FN_fin += FN\n",
    "                        \n",
    "\n",
    "\n",
    "# Average Precision & Recall\n",
    "AP = TP_fin/(TP_fin+FP_fin) \n",
    "Recall = TP_fin/(TP_fin+FN_fin)\n",
    "\n",
    "print('AP@0.5 : {0}%'.format(AP*100))\n",
    "print('Recall@0.5 : {0}%'.format(Recall * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
