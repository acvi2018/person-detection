{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "import warnings\n",
    "import shutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imageio\n",
    "# imageio.plugins.ffmpeg.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_boundaries(img_path, x1, y1, x2, y2):\n",
    "    img = cv2.imread(img_path)\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2BGRA)\n",
    "    plt.figure(figsize=(25,28))\n",
    "    plt.imshow(gray)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_boundaries('data/frames/1.1.1_frame_01523.jpg',2695,435,2743,514)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels: Each line contains 10+ columns, separated by spaces. The definition of these columns are:\n",
    "\n",
    "    Track ID. All rows with the same ID belong to the same person for 180 frames. Then the person gets a new idea for the next 180 frames. We will soon release an update to make the IDs consistant.\n",
    "    xmin. The top left x-coordinate of the bounding box.\n",
    "    ymin. The top left y-coordinate of the bounding box.\n",
    "    xmax. The bottom right x-coordinate of the bounding box.\n",
    "    ymax. The bottom right y-coordinate of the bounding box.\n",
    "    frame. The frame that this annotation represents.\n",
    "    lost. If 1, the annotation is outside of the view screen.\n",
    "    occluded. If 1, the annotation is occluded.\n",
    "    generated. If 1, the annotation was automatically interpolated.\n",
    "    label. The label for this annotation, enclosed in quotation marks. This field is always “Person”.\n",
    "    (+) actions. Each column after this is an action.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ffmpeg -i ../1.1.1.mov -start_number 0 frame_%05d.jpg\n",
    "def split_video(video_file, image_name_prefix, output_path):\n",
    "\treturn subprocess.check_output('ffmpeg -i ' + os.path.abspath(video_file) + ' '+ image_name_prefix +'%d.jpg', shell=True, cwd=os.path.join(destination_path, 'JPEGImages'))\\\n",
    "\n",
    "def convert_video_to_sequences(video_file_path, video_file_name, output_path):\n",
    "    image_list = None\n",
    "    if video_file_path is not None and output_path is not None:\n",
    "        video = VideoFileClip(video_file_path)\n",
    "        image_list = video.write_images_sequence('{0}/{1}_frame_%05d.jpg'.format(output_path, video_file_name), fps=None, verbose=True, withmask=True, progress_bar=True)\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create json file for a frame\n",
    "def create_frame_level_annotations(annotation_file, video_file_name, output_path):\n",
    "    # map {frame : list(annotations)}\n",
    "    sep = ' '\n",
    "    columns = ['track_id', 'xmin', 'ymin', 'xmax', 'ymax','frame','lost','occluded','generated','label','action']\n",
    "    cols_req = ['track_id', 'xmin', 'ymin', 'xmax', 'ymax','lost','occluded','generated','label','action']\n",
    "    annotation_df = pd.read_csv(annotation_file, sep=sep , names=columns, header=None)\n",
    "    \n",
    "    frames = annotation_df.frame.unique()\n",
    "    for frame in frames:\n",
    "        frame_df = annotation_df[np.logical_and(annotation_df.frame == frame, annotation_df.lost == 0)][cols_req]\n",
    "        with open('{0}/{1}_frame_{2:05d}.json'.format(output_path, video_file_name, frame), 'w') as fp:\n",
    "            json.dump(frame_df.T.to_dict().values(), fp)\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create_frame_level_annotations('data/Labels/SingleActionLabels/3840x2160/1.1.1.txt', '1.1.1','data/annotations')\n",
    "# convert_video_to_sequences('data/1.1.1.mov', '1.1.1', 'data/frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 2.1.6.mp4...\n",
      "[MoviePy] Writing frames /home/vijin/iith/project/data/okutama-action-drone-data/frames/2.1.6_frame_%05d.jpg."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1818it [07:40,  3.87it/s]                    "
     ]
    }
   ],
   "source": [
    "# create folder for frames and annotation : frame_name and annotation will be same\n",
    "# create metadata csv file with index which has information about frames and annotation <index, image_file_name, ann_file_name>\n",
    "\n",
    "root_video_folder = '/home/vijin/iith/project/data/okutama-action-drone-data/videos'\n",
    "root_annotation_folder = '/home/vijin/iith/project/data/okutama-action-drone-data/video-annotations'\n",
    "\n",
    "frame_output_folder = '/home/vijin/iith/project/data/okutama-action-drone-data/frames'\n",
    "ann_output_folder = '/home/vijin/iith/project/data/okutama-action-drone-data/annotations'\n",
    "root_folder = '/home/vijin/iith/project/data/okutama-action-drone-data'\n",
    "\n",
    "ann_ext = '.txt'\n",
    "\n",
    "meta_data = pd.DataFrame(columns=['id', 'img_file', 'ann_file'])\n",
    "file_counter = 0\n",
    "\n",
    "for x in os.listdir(root_video_folder):\n",
    "    video_file_name = x[0:x.rindex('.')]\n",
    "    video_file_path = '{0}/{1}'.format(root_video_folder, x)\n",
    "    ann_file = '{0}/{1}{2}'.format(root_annotation_folder, video_file_name, ann_ext)\n",
    "    \n",
    "    print('Processing {0}...'.format(x))\n",
    "    image_list = convert_video_to_sequences(video_file_path, video_file_name, frame_output_folder)\n",
    "\n",
    "    print('Creating frame level annotations...')\n",
    "    frames = create_frame_level_annotations(ann_file, video_file_name, ann_output_folder)\n",
    "    \n",
    "    meta_data_tup = []\n",
    "    for index, file_path in enumerate(image_list):\n",
    "        frame_number_search = re.search('.*_frame_(\\d+).jpg', file_path[file_path.rindex('/')+1 :], re.IGNORECASE)\n",
    "        if frame_number_search:\n",
    "            if int(frame_number_search.group(1)) in frames:\n",
    "                meta_data_tup.append((file_counter+index, file_path[file_path.rindex('/')+1 :],\n",
    "                      '{0}.json'.format(file_path[file_path.rindex('/')+1 :file_path.rindex('.')])))\n",
    "        \n",
    "#     meta_data_tup = [(file_counter+index, file_path[file_path.rindex('/')+1 :],\n",
    "#                       '{0}.json'.format(file_path[file_path.rindex('/')+1 :file_path.rindex('.')])) \n",
    "#                      for index, file_path in enumerate(image_list)]\n",
    "    meta_data = meta_data.append(pd.DataFrame(meta_data_tup, columns=['id', 'img_file', 'ann_file']), ignore_index=True)\n",
    "    \n",
    "    \n",
    "    file_counter = file_counter + len(image_list)\n",
    "    \n",
    "meta_data.to_csv('{0}/metadata.csv'.format(root_folder), index=False)\n",
    "print('Finished processing....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
